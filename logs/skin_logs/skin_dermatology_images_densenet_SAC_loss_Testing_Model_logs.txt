++++Use densenet model+++
starting!!!-----------------------------------------------
Accuracy: 0.6928104575163399
Sensitivity: 0.6941176470588235
Specificity: 0.6911764705882353
Precision: 0.7375
Ending!!!------------------------------------------------------
(0.6941176470588235, 0.6911764705882353)
Loss: SAC_loss class_name DaG Accuracy: 0.5974683544303797
              precision    recall  f1-score   support

           0       0.50      0.47      0.48       100
           1       0.56      0.50      0.53       118
           2       0.67      0.73      0.70       177

    accuracy                           0.60       395
   macro avg       0.57      0.57      0.57       395
weighted avg       0.59      0.60      0.59       395

=========== AUC: 0.679550169178411
++++Use densenet model+++
starting!!!-----------------------------------------------
Accuracy: 0.8471074380165289
Sensitivity: 0.3170731707317073
Specificity: 0.9552238805970149
Precision: 0.5909090909090909
Ending!!!------------------------------------------------------
(0.3170731707317073, 0.9552238805970149)
Loss: SAC_loss class_name PIG Accuracy: 0.6759493670886076
              precision    recall  f1-score   support

           0       0.70      0.86      0.77       223
           1       0.42      0.27      0.33        48
           2       0.68      0.50      0.58       124

    accuracy                           0.68       395
   macro avg       0.60      0.54      0.56       395
weighted avg       0.66      0.68      0.66       395

=========== AUC: 0.6670008964837387
++++Use densenet model+++
starting!!!-----------------------------------------------
Accuracy: 0.8178137651821862
Sensitivity: 0.8434782608695652
Specificity: 0.7954545454545454
Precision: 0.782258064516129
Ending!!!------------------------------------------------------
(0.8434782608695652, 0.7954545454545454)
Loss: SAC_loss class_name PN Accuracy: 0.6227848101265823
              precision    recall  f1-score   support

           0       0.74      0.67      0.71       156
           1       0.63      0.66      0.64       146
           2       0.44      0.47      0.46        93

    accuracy                           0.62       395
   macro avg       0.60      0.60      0.60       395
weighted avg       0.63      0.62      0.63       395

=========== AUC: 0.7074833695037077
++++Use densenet model+++
starting!!!-----------------------------------------------
Accuracy: 0.9109311740890689
Sensitivity: 0.5277777777777778
Specificity: 0.976303317535545
Precision: 0.7916666666666666
Ending!!!------------------------------------------------------
(0.5277777777777778, 0.976303317535545)
Loss: SAC_loss class_name STR Accuracy: 0.6556962025316456
              precision    recall  f1-score   support

           0       0.76      0.80      0.78       257
           1       0.54      0.43      0.48        44
           2       0.39      0.36      0.37        94

    accuracy                           0.66       395
   macro avg       0.56      0.53      0.54       395
weighted avg       0.65      0.66      0.65       395

=========== AUC: 0.6486383035344125
++++Use densenet model+++
starting!!!-----------------------------------------------
Accuracy: 0.859504132231405
Sensitivity: 0.19230769230769232
Specificity: 0.9710610932475884
Precision: 0.5263157894736842
Ending!!!------------------------------------------------------
(0.19230769230769232, 0.9710610932475884)
Loss: SAC_loss class_name VS Accuracy: 0.7924050632911392
              precision    recall  f1-score   support

           0       0.82      0.96      0.89       313
           1       0.42      0.19      0.26        52
           2       0.33      0.03      0.06        30

    accuracy                           0.79       395
   macro avg       0.52      0.40      0.40       395
weighted avg       0.73      0.79      0.74       395

=========== AUC: 0.5565539047178465
