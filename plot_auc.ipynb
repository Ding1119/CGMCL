{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from scipy import interp\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from itertools import cycle\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.linear import Linear\n",
    "from sklearn.cluster import KMeans\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from utils import build_knn_graph, label_return, plot_auc, print_auc, calculate_metrics_new, run_eval\n",
    "from model_resnet_skin import Projection, Model_SKIN, CNN\n",
    "from model_resnet_abide import Projection, Model_ABIDE, CNN\n",
    "from model_resnet_pd import Projection, Model_PD, CNN\n",
    "from losses import WeightedCrossEntropyLoss, contrastive_loss, info_loss, MGECLoss, SACLoss\n",
    "import argparse\n",
    "from data_handlder.load_dataset import dataloader\n",
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"0\"\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, auc\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import confusion_matrix, plot_roc_curve, roc_auc_score, roc_curve, auc, accuracy_score, precision_recall_fscore_support, jaccard_score\n",
    "\n",
    "\n",
    "class ClassifierPipeline(object): \n",
    "\n",
    "    def __init__(self, classifier_dict):\n",
    "        \"\"\"\n",
    "            Preprocessing should be done \n",
    "            Args: \n",
    "                dictionary of classifier, w its parameters\n",
    "                number of cross-validation folds\n",
    "        \"\"\"\n",
    "        self.classifier_dict = classifier_dict\n",
    "    \n",
    "    def fit(self, X, y, numfolds):\n",
    "        \"\"\"\n",
    "            Fit k-fold cross-validated classifier, store model metrics & create ROC plot\n",
    "            X: observation x features matrix\n",
    "            y: list of labels\n",
    "            folds: how many folds of cross-validation\n",
    "        \"\"\"\n",
    "        self.conf_matrix = {}\n",
    "        fig, ax = plt.subplots(figsize=(28,5), nrows=1, ncols=len(self.classifier_dict.keys()))\n",
    "\n",
    "        for c, (classifier_name, classifier) in enumerate(self.classifier_dict.items()):   \n",
    "            \n",
    "            print(f'Running {classifier_name} classification')\n",
    "        \n",
    "            # store this fold's outputs\n",
    "            k_accuracy = np.zeros((numfolds))\n",
    "            conf_mat = np.zeros((2,2)) \n",
    "\n",
    "            # for roc plot\n",
    "            tprs = []\n",
    "            aucs = []\n",
    "            mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "            cv = StratifiedKFold(n_splits=numfolds)  \n",
    "            for k, (train, test) in enumerate(cv.split(X, y)):\n",
    "                \n",
    "                # Create a clone of the classifier for each cross-validation\n",
    "                classifier_clone = clone(classifier)\n",
    "                if \"SVC\" in classifier_name:\n",
    "                    classifier_clone = CalibratedClassifierCV(classifier_clone)\n",
    "\n",
    "                # fit model & predict\n",
    "                classifier_clone.fit(X[train], y[train])\n",
    "                predictions = classifier_clone.predict(X[test])\n",
    "\n",
    "                # classifier metrics \n",
    "                k_accuracy[k] = classifier_clone.score(X[test], y[test])\n",
    "                conf_mat = conf_mat + confusion_matrix(y[test], predictions) # sum across folds\n",
    "                \n",
    "                # ROC plot for this fold\n",
    "                viz = plot_roc_curve(classifier_clone, X[test], y[test], name=f'ROC fold {k+1}', alpha=0.3, lw=1, ax=ax[c])\n",
    "                \n",
    "                # Store tpr and fpr values to calculate mean ROC at the end\n",
    "                interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "                interp_tpr[0] = 0.0\n",
    "                tprs.append(interp_tpr)\n",
    "                aucs.append(viz.roc_auc)\n",
    "\n",
    "            # Calculate mean ROC and plt  \n",
    "            mean_tpr = np.mean(tprs, axis=0)\n",
    "            mean_tpr[-1] = 1.0 \n",
    "            mean_auc = auc(mean_fpr, mean_tpr)\n",
    "            std_auc = np.std(aucs)\n",
    "            std_tpr = np.std(tprs, axis=0)\n",
    "            tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "            tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "            ax[c].plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "            ax[c].plot(mean_fpr, mean_tpr, color='b',\n",
    "                    label=f'Mean ROC (AUC={np.round(mean_auc, 2)} +/- {np.round(std_auc, 2)})',\n",
    "                    lw=2, alpha=.8)\n",
    "            ax[c].fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                    label=f'+/- 1 std. dev.')\n",
    "            ax[c].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title=f'{classifier_name} ROC')\n",
    "            ax[c].legend(loc=\"lower right\")\n",
    "    \n",
    "            self.conf_matrix[classifier_name] = conf_mat\n",
    "\n",
    "            # Print c.v. results\n",
    "            print(f\"{numfolds}-fold cross-validated accuracy: {np.round(np.mean(k_accuracy), 5)*100}%\")\n",
    "            print(k_accuracy)\n",
    "            print()\n",
    "            \n",
    "            # train each classifier with full data\n",
    "            classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_fit(X, y, model, numfolds):\n",
    "    \"\"\"\n",
    "    Fit k-fold cross-validated classifier, store model metrics & create ROC plot\n",
    "    X: observation x features matrix\n",
    "    y: list of labels\n",
    "    numfolds: how many folds of cross-validation\n",
    "    \"\"\"\n",
    "    conf_matrix = {}\n",
    "    fig, ax = plt.subplots(figsize=(28, 5), nrows=1)\n",
    "\n",
    "    print(f'Running {classifier_name} classification')\n",
    "\n",
    "    # store this fold's outputs\n",
    "    k_accuracy = np.zeros((numfolds))\n",
    "    conf_mat = np.zeros((2, 2))\n",
    "\n",
    "    # for roc plot\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=numfolds)\n",
    "    for k, (train, test) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X[train], X[test]\n",
    "        y_train, y_test = y[train], y[test]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        # classifier metrics\n",
    "        k_accuracy[k] = model.score(X_test, y_test)\n",
    "        conf_mat = conf_mat + confusion_matrix(y_test, predictions)  # sum across folds\n",
    "\n",
    "        # ROC plot for this fold\n",
    "        viz = plot_roc_curve(model, X_test, y_test, name=f'ROC fold {k + 1}', alpha=0.3, lw=1, ax=ax)\n",
    "\n",
    "        # Store tpr and fpr values to calculate mean ROC at the end\n",
    "        interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(viz.roc_auc)\n",
    "\n",
    "    # Calculate mean ROC and plot\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "    ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "            label=f'Mean ROC (AUC={np.round(mean_auc, 2)} +/- {np.round(std_auc, 2)})',\n",
    "            lw=2, alpha=.8)\n",
    "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                    label=f'+/- 1 std. dev.')\n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title=f'{classifier_name} ROC')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    conf_matrix[classifier_name] = conf_mat\n",
    "\n",
    "    # Print c.v. results\n",
    "    print(f\"{numfolds}-fold cross-validated accuracy: {np.round(np.mean(k_accuracy), 5) * 100}%\")\n",
    "    print(k_accuracy)\n",
    "    print()\n",
    "\n",
    "    # Train the classifier with the full data\n",
    "    model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jding/anaconda3/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/home/jding/anaconda3/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.29it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-23-3a4fa9d360af>(149)train_eval()\n",
      "-> print(f\"++++Use {model_select} model+++\")\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3a4fa9d360af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-3a4fa9d360af>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0mtrain_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskin_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_choice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_select\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_choice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;31m#     train_eval(args.img_data_dir, args.skin_type, args.losses_choice, args.model_select, args.dataset_choice,args.category, args.n_epoch, args.n_classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-3a4fa9d360af>\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m(datadir, skin_type, loss_select, model_select, dataset_choice, category, epoch, n_classes)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"++++Use {model_select} model+++\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_metrics_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_select\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"class_name\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-3a4fa9d360af>\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m(datadir, skin_type, loss_select, model_select, dataset_choice, category, epoch, n_classes)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"++++Use {model_select} model+++\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_metrics_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_select\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"class_name\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def train_eval(datadir,skin_type, loss_select, model_select , dataset_choice ,category, epoch, n_classes):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   \n",
    "    torch.cuda.is_available()\n",
    "    if model_select == 'resnet_18':\n",
    "        model_net = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        # resnet = models.resnet18(pretrained=True)\n",
    "    elif model_select == 'resnet_34':\n",
    "         model_net = models.resnet34(pretrained=True)\n",
    "    elif model_select == 'resnet_50':\n",
    "        model_net = models.resnet50(pretrained=True)\n",
    "    elif model_select == 'densenet':\n",
    "         model_net = models.densenet121(pretrained=True)\n",
    "        \n",
    "    #resnet = models.alexnet(pretrained=True)\n",
    "    \n",
    "    model_net = model_net.to(device)\n",
    "    # 将最后一层的输出维度修改为类别数目\n",
    "    num_classes = 1024\n",
    "    \n",
    "    # num_features = model_net.fc.in_features #512 # Resnet\n",
    "    num_features = model_net.classifier.in_features # Desnet101\n",
    "    # import pdb;pdb.set_trace()\n",
    "    # model_net.fc = nn.Linear(num_features, num_classes) #512 # Resnet\n",
    "    # model_net.fc = model_net.fc.to(device) #512 # Resnet\n",
    "    model_net.classifier = nn.Linear(num_features, num_classes) #desnet\n",
    "\n",
    "    image_data_train, feature_data_train, adj_train_img, adj_f_knn_train, image_data_test, test_feature_data, adj_test_img, adj_f_knn_test = dataloader(datadir,skin_type)\n",
    "\n",
    "    projection = Projection(262, 3)\n",
    "    if datadir == 'skin':\n",
    "        model = Model_SKIN(projection, model_net, n_classes).to(device)\n",
    "    elif datadir == 'abide':\n",
    "        model = Model_ABIDE(projection, model_net, n_classes).to(device)\n",
    "    elif datadir == 'pd':\n",
    "        model = Model_PD(projection, model_net, n_classes).to(device)\n",
    "\n",
    "    class_weights = torch.full((1,n_classes),0.5).view(-1)\n",
    "    criterion1 = WeightedCrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    if loss_select == 'Contrastive_loss':\n",
    "         criterion2 = contrastive_loss\n",
    "\n",
    "    elif loss_select == 'MGEC_loss':\n",
    "        criterion2 = MGECLoss()\n",
    "        \n",
    "    elif loss_select == 'InfoNCE_loss':\n",
    "        criterion2 = info_loss\n",
    "        \n",
    "    elif loss_select == 'SAC_loss':\n",
    "        criterion2 = SACLoss()\n",
    "\n",
    "    # criterion3 = loss_dependence\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    class_name = \"Dag\"\n",
    "    n_epochs = epoch\n",
    "\n",
    "    training_range = tqdm(range(n_epochs))\n",
    "\n",
    "    for epoch in training_range:\n",
    "        optimizer.zero_grad()\n",
    "        # cnn_z  =  cnn_encoder(image_data)\n",
    "        # 前向传播\n",
    "        \n",
    "        image_data_train = image_data_train.to(device)\n",
    "        feature_data_train = feature_data_train.to(device)\n",
    "        adj_train_img = adj_train_img.to(device)\n",
    "        adj_f_knn_train = adj_f_knn_train.to(device)\n",
    "\n",
    "        output1, output2, emb = model(image_data_train , feature_data_train,adj_train_img, adj_f_knn_train)\n",
    "         \n",
    "        y = torch.tensor(label_return(dataset_choice, class_name, \"train\")).to(device)\n",
    "        \n",
    "        loss_ce1 = criterion1(output1, y)\n",
    "        loss_ce2 = criterion1(output2, y)\n",
    "        alpha = 0.4\n",
    "\n",
    "        if loss_select == 'Contrastive_loss':\n",
    "            adj = adj_train_img +  adj_f_knn_train\n",
    "            diag = torch.diag(adj.sum(dim=1))\n",
    "            loss_extra = criterion2( emb, adj_train_img, adj_f_knn_train, y, output1, output2, diag).to(device)\n",
    "            loss = (1-alpha)*(loss_ce1 + loss_ce2) + alpha* loss_extra\n",
    "\n",
    "        elif loss_select == 'MGEC_loss':\n",
    "            adj = adj_train_img +  adj_f_knn_train\n",
    "            diag = torch.diag(adj.sum(dim=1))\n",
    "            loss_extra = criterion2(output1, output2, adj, diag )\n",
    "            loss = (1-alpha)*(loss_ce1+loss_ce2) + alpha* loss_extra\n",
    "            #loss = loss_extra\n",
    "\n",
    "        elif loss_select == 'InfoNCE_loss':\n",
    "            loss_extra = criterion2( emb, adj_train_img, adj_f_knn_train, y)\n",
    "            loss = (1-alpha)*(loss_ce1+loss_ce2) + alpha* loss_extra\n",
    "\n",
    "        elif loss_select == 'SAC_loss':    \n",
    "            adj = adj_train_img +  adj_f_knn_train\n",
    "            diag = torch.diag(adj.sum(dim=1))\n",
    "            loss_extra = criterion2(emb, adj)\n",
    "            loss = (1-alpha)*(loss_ce1+loss_ce2) + alpha* loss_extra\n",
    "        elif loss_select == 'only_CE':\n",
    "            loss = loss_ce1 + loss_ce2\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # torch.save(model,f'{skin_type}_{epoch}epoch_save.pt')\n",
    "        # print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, n_epochs, loss.item()))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # import pdb;pdb.set_trace()\n",
    "        image_data_test = image_data_test.to(device)\n",
    "        test_feature_data = test_feature_data.to(device)\n",
    "        adj_test_img = adj_test_img.to(device)\n",
    "        adj_f_knn_test = adj_f_knn_test.to(device)\n",
    "        \n",
    "        test_output1, test_output2, emb  = model(image_data_test, test_feature_data , adj_test_img, adj_f_knn_test )\n",
    "\n",
    "        # test_output1  = model(test_image_data, test_adjacency_matrix, adj_test_img )\n",
    "        m = nn.Softmax(dim=1)\n",
    "        # import pdb;pdb.set_trace()\n",
    "        test_output = test_output1 + test_output2\n",
    "    #     test_output = emb\n",
    "\n",
    "        #z = test_output1 + test_output2\n",
    "        \n",
    "        #num_clusters = 3\n",
    "        #kmeans = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "        #cluster_labels = kmeans.fit_predict(z.cpu().data.numpy())\n",
    "        #cluster_labels = torch.tensor(cluster_labels,dtype=torch.int64).to(device)\n",
    "\n",
    "\n",
    "\n",
    "        pred =  m(test_output).argmax(dim=1)\n",
    "        #pred = cluster_labels\n",
    "        # test_output = test_output.argmax(dim=1)\n",
    "        \n",
    "        \n",
    "        # y_test = torch.empty(100).random_(2)\n",
    "    #     y_test = torch.tensor(label_3_test).to(device)\n",
    "        y_test = torch.from_numpy(label_return(dataset_choice ,class_name, \"test\")).to(device)\n",
    "\n",
    "        # import pdb;pdb.set_trace()\n",
    "        correct = (pred  == y_test).sum().item()\n",
    "        accuracy = correct / len(y_test)\n",
    "        \n",
    "        \n",
    "        import pdb;pdb.set_trace()\n",
    "        print(f\"++++Use {model_select} model+++\")\n",
    "        print(calculate_metrics_new(y_test.cpu().detach().numpy(), pred.cpu().detach().numpy() ))\n",
    "        print(\"Loss:\", loss_select, \"class_name\",class_name,\"Accuracy:\", accuracy)\n",
    "        print(classification_report(y_test.cpu().detach().numpy(), pred.cpu().detach().numpy() ))\n",
    "        if datadir == 'pd':\n",
    "            accuracy, precision, recall, fscore, sensivity, specificity, nmi, ari = run_eval(y_test.cpu().detach().numpy(), pred.cpu().detach().numpy())\n",
    "            print(\"acc:\",accuracy, \"precision:\", precision,\"recall:\", recall,\"fscore:\", fscore,\"sensitivity:\", sensivity,\"specificity:\", specificity, \"nmi\", nmi, \"ari\", ari)\n",
    "            # plot_ROC(pred.cpu().detach().numpy() , y_test.cpu().detach().numpy(), 3, classes, skin_type, loss_select)\n",
    "            # print_auc(pred.cpu().detach().numpy() , y_test.cpu().detach().numpy(), 3, category, skin_type, loss_select)\n",
    "\n",
    "def main():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--img_data_dir', type=str, default='pd')\n",
    "#     parser.add_argument('--skin_type', type=str, default='dermatology_images')\n",
    "#     #parser.add_argument('--meta_data_dir', type=str, default='/home/feng/jeding/PD_contrastive_research_0817/meta_ok/')\n",
    "#     parser.add_argument('--model_select', type=str, default='densenet')\n",
    "#     parser.add_argument('--losses_choice', type=str, default='Contrastive_loss')\n",
    "#     parser.add_argument('--dataset_choice', type=str, default='pd')\n",
    "#     parser.add_argument('--category', type=str)\n",
    "#     parser.add_argument('--n_epoch', type=int, default=300)\n",
    "#     parser.add_argument('--n_classes', type=int, default=2)\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "\n",
    "    img_data_dir = 'pd'\n",
    "    skin_type = 'dermatology_images'\n",
    "    losses_choice = 'Contrastive_loss'\n",
    "    model_select = 'densenet'\n",
    "    dataset_choice = 'pd'\n",
    "    category = 'your_category'  # 设置正确的类别值\n",
    "    n_epoch = 3\n",
    "    n_classes = 2\n",
    "\n",
    "    train_eval(img_data_dir, skin_type, losses_choice, model_select, dataset_choice, category, n_epoch, n_classes)\n",
    "#     train_eval(args.img_data_dir, args.skin_type, args.losses_choice, args.model_select, args.dataset_choice,args.category, args.n_epoch, args.n_classes)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(datadir,skin_type):\n",
    "\n",
    "    \n",
    "\n",
    "    if datadir == 'pd':\n",
    "        path_img = '/home/jding/Documents/PD_contrastive_research_0817/spect_513_data'+ '/'\n",
    "        path_meta = '/home/jding/Documents/PD_contrastive_research_0817/spect_513_data' + '/' \n",
    "        coll = io.ImageCollection('/home/jding/Documents/PD_contrastive_research_0817/spect_513_data/spect_img_a2/*.jpg')\n",
    "\n",
    "        #coll = io.ImageCollection(r'C:\\Users\\adm\\SPECT_3_3\\mask_three\\*.jpg')\n",
    "        #coll = io.ImageCollection(r'C:\\Users\\adm\\SPECT_3_3\\all_SPECT_RGB\\*.jpg')\n",
    "        raw_image = io.concatenate_images(coll)\n",
    "\n",
    "        \n",
    "        raw_meta = pd.read_csv(path_meta  + 'label_513.csv') \n",
    "        label_630_id = raw_meta[raw_meta['ID'] < 634]\n",
    "        raw_data = raw_image[label_630_id['Python_ID']] / 255\n",
    "\n",
    "        raw_data = torch.tensor(raw_data).transpose(1,3)\n",
    "        # raw_data = torch.flatten(raw_data, start_dim=1)\n",
    "        raw_data = np.array(raw_data)\n",
    "        raw_patients_feature_412 = np.asarray(label_630_id.iloc[:,8:20])\n",
    "\n",
    "        \n",
    "        raw_image_train = raw_data[0:300]\n",
    "        raw_image_test = raw_data[300:]\n",
    "        \n",
    "        # raw_image_train = np.load('/Users/test/Documents/Contrastive_PD/skin_dataset_ok/clinical_images/train_clinic_f_413.npy') /255\n",
    "        # raw_image_test = np.load('/Users/test/Documents/Contrastive_PD/skin_dataset_ok/clinical_images/test_clinic_f_395.npy') /255\n",
    "        \n",
    "\n",
    "        raw_f_train = raw_patients_feature_412[0:300]\n",
    "        raw_f_test = raw_patients_feature_412[300:]\n",
    "        # raw_f_train = preprocessing.scale(raw_f_train )\n",
    "        # raw_f_test = preprocessing.scale(raw_f_test )\n",
    "        \n",
    "        image_data_train = raw_image_train \n",
    "        feature_data_train = raw_f_train \n",
    "        \n",
    "        \n",
    "        image_data_train = torch.from_numpy(image_data_train ).float() #torch.Size([413, 128, 128, 3])\n",
    "        \n",
    "        \n",
    "        feature_data_train = torch.from_numpy(feature_data_train).float()\n",
    "\n",
    "        image_data_flatten = torch.flatten(image_data_train, start_dim=1)\n",
    "\n",
    "        # import pdb;pdb.set_trace()\n",
    "        adj_train_img = build_knn_graph(image_data_flatten,300).float()\n",
    "        \n",
    "        # adj_train_img = kneighbors_graph(np.array(image_data_flatten), 200, mode='connectivity', include_self=True).toarray()\n",
    "\n",
    "        \n",
    "        \n",
    "        # adj_train_img = torch.from_numpy(adj_train_img).float()\n",
    "        \n",
    "        \n",
    "        image_data_test = torch.from_numpy(raw_image_test ).float()\n",
    "    \n",
    "        data_features_test = raw_f_test \n",
    "        test_feature_data = torch.from_numpy(data_features_test).float()\n",
    "\n",
    "    # 创建测试用的邻接矩阵（这里假设所有病人之间都有连接）\n",
    "    # test_adjacency_matrix = torch.ones((100, 100))\n",
    "\n",
    "\n",
    "    ## testing image adj\n",
    "        image_data_test_flatten = torch.flatten(image_data_test, start_dim=1)\n",
    "        # image_data_test_flatten = image_data_test\n",
    "  \n",
    "        # adj_test_img = kneighbors_graph(np.array(image_data_test_flatten), 200, mode='connectivity', include_self=True).toarray()\n",
    "        \n",
    "        adj_test_img = build_knn_graph(image_data_test_flatten, 80).float() #[104, 104]\n",
    "\n",
    "        \n",
    "        adj_f_knn_train =  build_knn_graph(raw_f_train, 300).float()\n",
    "        \n",
    "        # adj_f_knn_train = adj_f_knn_train.toarray()\n",
    "        # adj_f_knn_train = torch.from_numpy(adj_f_knn_train).float()\n",
    "        # adj_f_knn_test = kneighbors_graph(np.array(raw_f_test), 300, mode='connectivity', include_self=True)\n",
    "        adj_f_knn_test = build_knn_graph(raw_f_test, 80).float()\n",
    "        # import pdb;pdb.set_trace()\n",
    "\n",
    "       \n",
    "    return image_data_train, feature_data_train, adj_train_img, adj_f_knn_train, image_data_test, test_feature_data, adj_test_img, adj_f_knn_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修改後dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from scipy import interp\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from itertools import cycle\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.linear import Linear\n",
    "from sklearn.cluster import KMeans\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from utils import build_knn_graph, label_return, plot_auc, print_auc, calculate_metrics_new, run_eval\n",
    "from model_resnet_skin import Projection, Model_SKIN, CNN\n",
    "from model_resnet_abide import Projection, Model_ABIDE, CNN\n",
    "from model_resnet_pd import Projection, Model_PD, CNN\n",
    "from losses import WeightedCrossEntropyLoss, contrastive_loss, info_loss, MGECLoss, SACLoss\n",
    "import argparse\n",
    "from data_handlder.load_dataset import dataloader\n",
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"0\"\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, auc\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import confusion_matrix, plot_roc_curve, roc_auc_score, roc_curve, auc, accuracy_score, precision_recall_fscore_support, jaccard_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from skimage import data_dir,io,color\n",
    "\n",
    "def dataloader_cv(datadir, skin_type, num_folds=5):\n",
    "    \n",
    "    if datadir == 'pd':\n",
    "        path_img = '/home/jding/Documents/PD_contrastive_research_0817/spect_513_data' + '/'\n",
    "        path_meta = '/home/jding/Documents/PD_contrastive_research_0817/spect_513_data' + '/'\n",
    "        coll = io.ImageCollection('/home/jding/Documents/PD_contrastive_research_0817/spect_513_data/spect_img_a2/*.jpg')\n",
    "\n",
    "        raw_image = io.concatenate_images(coll)\n",
    "\n",
    "        raw_meta = pd.read_csv(path_meta + 'label_513.csv')\n",
    "        label_630_id = raw_meta[raw_meta['ID'] < 634]\n",
    "        raw_data = raw_image[label_630_id['Python_ID']] / 255\n",
    "        raw_data = torch.tensor(raw_data).transpose(1, 3)\n",
    "        raw_data = np.array(raw_data)\n",
    "        raw_patients_feature_412 = np.asarray(label_630_id.iloc[:, 8:20])\n",
    "#         import pdb;pdb.set_trace()\n",
    "        # 创建 StratifiedKFold 对象\n",
    "        skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "        image_data_train_list = []\n",
    "        feature_data_train_list = []\n",
    "        adj_train_img_list = []\n",
    "        adj_f_knn_train_list = []\n",
    "        image_data_test_list = []\n",
    "        test_feature_data_list = []\n",
    "        adj_test_img_list = []\n",
    "        adj_f_knn_test_list = []\n",
    "        y_train_list = []\n",
    "        y_test_list = []\n",
    "#         import pdb;pdb.set_trace()\n",
    "        for train_index, test_index in skf.split(raw_data, label_630_id['Label_2'].values):\n",
    "            y_train = label_630_id['Label_2'].values[train_index]\n",
    "            y_test = label_630_id['Label_2'].values[test_index]\n",
    "            # 根据每个折叠的索引提取相应的训练和测试数据\n",
    "            raw_image_train = raw_data[train_index]\n",
    "            raw_image_test = raw_data[test_index]\n",
    "\n",
    "            raw_f_train = raw_patients_feature_412[train_index]\n",
    "            raw_f_test = raw_patients_feature_412[test_index]\n",
    "\n",
    "            image_data_train = torch.from_numpy(raw_image_train).float()\n",
    "            feature_data_train = torch.from_numpy(raw_f_train).float()\n",
    "            image_data_flatten = torch.flatten(image_data_train, start_dim=1)\n",
    "            adj_train_img = build_knn_graph(image_data_flatten, len(train_index)).float()\n",
    "\n",
    "            image_data_test = torch.from_numpy(raw_image_test).float()\n",
    "            data_features_test = raw_f_test\n",
    "            test_feature_data = torch.from_numpy(data_features_test).float()\n",
    "\n",
    "            image_data_test_flatten = torch.flatten(image_data_test, start_dim=1)\n",
    "            adj_test_img = build_knn_graph(image_data_test_flatten, len(test_index)).float()\n",
    "            adj_f_knn_train = build_knn_graph(raw_f_train, len(train_index)).float()\n",
    "            adj_f_knn_test = build_knn_graph(raw_f_test, len(test_index)).float()\n",
    "\n",
    "            # 将每个折叠的数据添加到列表中\n",
    "            y_train_list.append(y_train)\n",
    "            y_test_list.append(y_test)\n",
    "            image_data_train_list.append(image_data_train)\n",
    "            feature_data_train_list.append(feature_data_train)\n",
    "            adj_train_img_list.append(adj_train_img)\n",
    "            adj_f_knn_train_list.append(adj_f_knn_train)\n",
    "            image_data_test_list.append(image_data_test)\n",
    "            test_feature_data_list.append(test_feature_data)\n",
    "            adj_test_img_list.append(adj_test_img)\n",
    "            adj_f_knn_test_list.append(adj_f_knn_test)\n",
    "\n",
    "    return image_data_train_list, feature_data_train_list, adj_train_img_list, \\\n",
    "        adj_f_knn_train_list, image_data_test_list, test_feature_data_list, \\\n",
    "        adj_test_img_list, adj_f_knn_test_list, y_train_list ,y_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list, \\\n",
    "y_test_list, \\\n",
    "image_data_train,\\\n",
    "feature_data_train, \\\n",
    "adj_train_img, \\\n",
    "adj_f_knn_train, image_data_test, test_feature_data, \\\n",
    "adj_test_img, adj_f_knn_test = dataloader_cv('pd', 'dermatology_images', num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "        0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "        0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "        0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "        1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "        0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "        1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0]),\n",
       " array([0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "        1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "        0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "        0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0]),\n",
       " array([0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "        0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "        1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "        0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "        1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "        1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "        0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1]),\n",
       " array([1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "        0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0]),\n",
       " array([0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "        0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "        0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "        0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "        1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "        0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mage_data_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([329, 3, 128, 128])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mage_data_train_list[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jding/anaconda3/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/home/jding/anaconda3/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:00<00:01,  2.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:01,  2.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:01<00:00,  2.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:01<00:00,  2.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++Use densenet model+++\n",
      "starting!!!-----------------------------------------------\n",
      "Accuracy: 0.4939759036144578\n",
      "Sensitivity: 0.9512195121951219\n",
      "Specificity: 0.047619047619047616\n",
      "Precision: 0.4936708860759494\n",
      "Ending!!!------------------------------------------------------\n",
      "(0.9512195121951219, 0.047619047619047616)\n",
      "Loss: Contrastive_loss class_name Dag Accuracy: 0.4939759036144578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.05      0.09        42\n",
      "           1       0.49      0.95      0.65        41\n",
      "\n",
      "    accuracy                           0.49        83\n",
      "   macro avg       0.50      0.50      0.37        83\n",
      "weighted avg       0.50      0.49      0.37        83\n",
      "\n",
      "ARI: -0.0022158333917677584\n",
      "acc: 0.4939759036144578 precision: 0.4936708860759494 recall: 0.9512195121951219 fscore: 0.65 sensitivity: 0.9512195121951219 specificity: 0.047619047619047616 nmi 8.293952762296809e-06 ari -0.0022158333917677584\n",
      "Fold 2/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  2.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [00:00<00:00,  2.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:01<00:00,  2.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "/home/jding/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jding/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jding/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++Use densenet model+++\n",
      "starting!!!-----------------------------------------------\n",
      "Accuracy: 0.4939759036144578\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.0\n",
      "Precision: 0.4939759036144578\n",
      "Ending!!!------------------------------------------------------\n",
      "(1.0, 0.0)\n",
      "Loss: Contrastive_loss class_name Dag Accuracy: 0.4939759036144578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        42\n",
      "           1       0.49      1.00      0.66        41\n",
      "\n",
      "    accuracy                           0.49        83\n",
      "   macro avg       0.25      0.50      0.33        83\n",
      "weighted avg       0.24      0.49      0.33        83\n",
      "\n",
      "ARI: 0.0\n",
      "acc: 0.4939759036144578 precision: 0.4939759036144578 recall: 1.0 fscore: 0.6612903225806451 sensitivity: 1.0 specificity: 0.0 nmi 1.922257186801058e-15 ari 0.0\n",
      "Fold 3/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "/home/jding/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jding/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jding/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++Use densenet model+++\n",
      "starting!!!-----------------------------------------------\n",
      "Accuracy: 0.4878048780487805\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.0\n",
      "Precision: 0.4878048780487805\n",
      "Ending!!!------------------------------------------------------\n",
      "(1.0, 0.0)\n",
      "Loss: Contrastive_loss class_name Dag Accuracy: 0.4878048780487805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        42\n",
      "           1       0.49      1.00      0.66        40\n",
      "\n",
      "    accuracy                           0.49        82\n",
      "   macro avg       0.24      0.50      0.33        82\n",
      "weighted avg       0.24      0.49      0.32        82\n",
      "\n",
      "ARI: 0.0\n",
      "acc: 0.4878048780487805 precision: 0.4878048780487805 recall: 1.0 fscore: 0.6557377049180327 sensitivity: 1.0 specificity: 0.0 nmi 0.0 ari 0.0\n",
      "Fold 4/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 1/2 [00:00<00:00,  2.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "/home/jding/Documents/PD_contrastive_research_0817/utils.py:156: RuntimeWarning: invalid value encountered in true_divide\n",
      "  print('Precision:',TP / float(TP + FP))\n",
      "/home/jding/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jding/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jding/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jding/Documents/PD_contrastive_research_0817/utils.py:30: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = TP / (TP + FP)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++Use densenet model+++\n",
      "starting!!!-----------------------------------------------\n",
      "Accuracy: 0.5\n",
      "Sensitivity: 0.0\n",
      "Specificity: 1.0\n",
      "Precision: nan\n",
      "Ending!!!------------------------------------------------------\n",
      "(0.0, 1.0)\n",
      "Loss: Contrastive_loss class_name Dag Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        41\n",
      "           1       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.50        82\n",
      "   macro avg       0.25      0.50      0.33        82\n",
      "weighted avg       0.25      0.50      0.33        82\n",
      "\n",
      "ARI: 0.0\n",
      "acc: 0.5 precision: nan recall: 0.0 fscore: 0.0 sensitivity: 0.0 specificity: 1.0 nmi 0.0 ari 0.0\n",
      "Fold 5/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++Use densenet model+++\n",
      "starting!!!-----------------------------------------------\n",
      "Accuracy: 0.23170731707317074\n",
      "Sensitivity: 0.1951219512195122\n",
      "Specificity: 0.2682926829268293\n",
      "Precision: 0.21052631578947367\n",
      "Ending!!!------------------------------------------------------\n",
      "(0.1951219512195122, 0.2682926829268293)\n",
      "Loss: Contrastive_loss class_name Dag Accuracy: 0.23170731707317074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.27      0.26        41\n",
      "           1       0.21      0.20      0.20        41\n",
      "\n",
      "    accuracy                           0.23        82\n",
      "   macro avg       0.23      0.23      0.23        82\n",
      "weighted avg       0.23      0.23      0.23        82\n",
      "\n",
      "ARI: 0.2790711508004372\n",
      "acc: 0.23170731707317074 precision: 0.21052631578947367 recall: 0.1951219512195122 fscore: 0.20253164556962025 sensitivity: 0.1951219512195122 specificity: 0.2682926829268293 nmi 0.22102761833220813 ari 0.2790711508004372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC: 0.51\n",
      "Standard Deviation of AUC: 0.32\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def train_eval(datadir,skin_type, loss_select, model_select , dataset_choice ,category, epoch, n_classes):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   \n",
    "    torch.cuda.is_available()\n",
    "    \n",
    "    class_name = 'Dag'\n",
    "    if model_select == 'resnet_18':\n",
    "        model_net = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        # resnet = models.resnet18(pretrained=True)\n",
    "    elif model_select == 'resnet_34':\n",
    "         model_net = models.resnet34(pretrained=True)\n",
    "    elif model_select == 'resnet_50':\n",
    "        model_net = models.resnet50(pretrained=True)\n",
    "    elif model_select == 'densenet':\n",
    "         model_net = models.densenet121(pretrained=True)\n",
    "        \n",
    "    #resnet = models.alexnet(pretrained=True)\n",
    "    \n",
    "    model_net = model_net.to(device)\n",
    "    # 将最后一层的输出维度修改为类别数目\n",
    "    num_classes = 1024\n",
    "    \n",
    "    # num_features = model_net.fc.in_features #512 # Resnet\n",
    "    num_features = model_net.classifier.in_features # Desnet101\n",
    "    # import pdb;pdb.set_trace()\n",
    "    # model_net.fc = nn.Linear(num_features, num_classes) #512 # Resnet\n",
    "    # model_net.fc = model_net.fc.to(device) #512 # Resnet\n",
    "    model_net.classifier = nn.Linear(num_features, num_classes) #desnet\n",
    "    \n",
    "    image_data_train_list, feature_data_train_list, adj_train_img_list, \\\n",
    "    adj_f_knn_train_list, image_data_test_list, test_feature_data_list, \\\n",
    "    adj_test_img_list, adj_f_knn_test_list, y_train_list ,y_test_list = dataloader_cv(datadir,skin_type, num_folds=5)\n",
    " \n",
    "#     image_data_train, feature_data_train, adj_train_img, adj_f_knn_train, image_data_test, test_feature_data, adj_test_img, adj_f_knn_test = dataloader(datadir,skin_type)\n",
    "    \n",
    "    \n",
    "    all_aucs = []\n",
    "    all_fpr = []\n",
    "    all_tpr = []\n",
    "    all_roc_auc = []\n",
    "    false_positives = []  # 用于存储 False Positives 的样本 ID\n",
    "    false_negatives = []  # 用于存储 False Negatives 的样本 ID\n",
    "\n",
    "    for fold in range(len(image_data_train_list)):\n",
    "        print(f\"Fold {fold + 1}/{len(image_data_train_list)}:\")\n",
    "        \n",
    "        image_data_train = image_data_train_list[fold]\n",
    "        feature_data_train = feature_data_train_list[fold]\n",
    "        adj_train_img = adj_train_img_list[fold]\n",
    "        adj_f_knn_train = adj_f_knn_train_list[fold]\n",
    "        image_data_test = image_data_test_list[fold]\n",
    "        test_feature_data = test_feature_data_list[fold]\n",
    "        adj_test_img = adj_test_img_list[fold]\n",
    "        adj_f_knn_test = adj_f_knn_test_list[fold]\n",
    "        \n",
    "        y_train = y_train_list[fold]\n",
    "        y_test = y_test_list[fold]\n",
    "     \n",
    "        image_data_train = image_data_train.to(torch.float32).to(device)\n",
    "        feature_data_train = feature_data_train.to(torch.float32).to(device)\n",
    "        # import pdb;pdb.set_trace()\n",
    "        adj_train_img = adj_train_img.to(torch.float32).to(device)\n",
    "        adj_f_knn_train = adj_f_knn_train.to(torch.float32).to(device)\n",
    "        image_data_test = image_data_test.to(torch.float32).to(device)\n",
    "        test_feature_data = test_feature_data.to(torch.float32).to(device)\n",
    "        adj_test_img = adj_test_img.to(torch.float32).to(device)\n",
    "        adj_f_knn_test = adj_f_knn_test.to(torch.float32).to(device)\n",
    "\n",
    "        # y_train = y_train.to(device)\n",
    "        # y_test = y_test.to(device)\n",
    "        \n",
    "        # import pdb;pdb.set_trace()\n",
    "\n",
    "\n",
    "        projection = Projection(262, 3)\n",
    "        if datadir == 'skin':\n",
    "            model = Model_SKIN(projection, model_net, n_classes).to(device)\n",
    "        elif datadir == 'abide':\n",
    "            model = Model_ABIDE(projection, model_net, n_classes).to(device)\n",
    "        elif datadir == 'pd':\n",
    "            model = Model_PD(projection, model_net, n_classes).to(device, dtype=torch.float32)\n",
    "\n",
    "        class_weights = torch.full((1,n_classes),0.5).view(-1)\n",
    "        criterion1 = WeightedCrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "        if loss_select == 'Contrastive_loss':\n",
    "             criterion2 = contrastive_loss\n",
    "\n",
    "        elif loss_select == 'MGEC_loss':\n",
    "            criterion2 = MGECLoss()\n",
    "\n",
    "        elif loss_select == 'InfoNCE_loss':\n",
    "            criterion2 = info_loss\n",
    "\n",
    "        elif loss_select == 'SAC_loss':\n",
    "            criterion2 = SACLoss()\n",
    "\n",
    "    # criterion3 = loss_dependence\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        n_epochs = epoch\n",
    "\n",
    "        training_range = tqdm(range(n_epochs))\n",
    "\n",
    "        for epoch in training_range:\n",
    "            optimizer.zero_grad()\n",
    "            # cnn_z  =  cnn_encoder(image_data)\n",
    "            # 前向传播\n",
    "\n",
    "            # image_data_train = image_data_train.to(device)\n",
    "            # feature_data_train = feature_data_train.to(device)\n",
    "            # adj_train_img = adj_train_img.to(device)\n",
    "            # adj_f_knn_train = adj_f_knn_train.to(device)\n",
    "            \n",
    "            output1, output2, emb = model(image_data_train , feature_data_train,adj_train_img, adj_f_knn_train)\n",
    "      \n",
    "            \n",
    "            y = torch.from_numpy(y_train).to(torch.int64).to(device)\n",
    "\n",
    "            loss_ce1 = criterion1(output1, y)\n",
    "            loss_ce2 = criterion1(output2, y)\n",
    "            alpha = 0.4\n",
    "\n",
    "            if loss_select == 'Contrastive_loss':\n",
    "                adj = adj_train_img +  adj_f_knn_train\n",
    "                diag = torch.diag(adj.sum(dim=1))\n",
    "                loss_extra = criterion2( emb, adj_train_img, adj_f_knn_train, y, output1, output2, diag).to(device)\n",
    "                loss = (1-alpha)*(loss_ce1 + loss_ce2) + alpha* loss_extra\n",
    "\n",
    "            elif loss_select == 'MGEC_loss':\n",
    "                adj = adj_train_img +  adj_f_knn_train\n",
    "                diag = torch.diag(adj.sum(dim=1))\n",
    "                loss_extra = criterion2(output1, output2, adj, diag )\n",
    "                loss = (1-alpha)*(loss_ce1+loss_ce2) + alpha* loss_extra\n",
    "                #loss = loss_extra\n",
    "\n",
    "            elif loss_select == 'InfoNCE_loss':\n",
    "                loss_extra = criterion2( emb, adj_train_img, adj_f_knn_train, y)\n",
    "                loss = (1-alpha)*(loss_ce1+loss_ce2) + alpha* loss_extra\n",
    "\n",
    "            elif loss_select == 'SAC_loss':    \n",
    "                adj = adj_train_img +  adj_f_knn_train\n",
    "                diag = torch.diag(adj.sum(dim=1))\n",
    "                loss_extra = criterion2(emb, adj)\n",
    "                loss = (1-alpha)*(loss_ce1+loss_ce2) + alpha* loss_extra\n",
    "            elif loss_select == 'only_CE':\n",
    "                loss = loss_ce1 + loss_ce2\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # torch.save(model,f'{skin_type}_{epoch}epoch_save.pt')\n",
    "            # print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, n_epochs, loss.item()))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # import pdb;pdb.set_trace()\n",
    "#             image_data_test = image_data_test.to(device)\n",
    "#             test_feature_data = test_feature_data.to(device)\n",
    "#             adj_test_img = adj_test_img.to(device)\n",
    "#             adj_f_knn_test = adj_f_knn_test.to(device)\n",
    "            # import pdb;pdb.set_trace()\n",
    "            test_output1, test_output2, emb  = model(image_data_test, test_feature_data , adj_test_img, adj_f_knn_test )\n",
    "\n",
    "            # test_output1  = model(test_image_data, test_adjacency_matrix, adj_test_img )\n",
    "            m = nn.Softmax(dim=1)\n",
    "            # import pdb;pdb.set_trace()\n",
    "            test_output = test_output1 + test_output2\n",
    "        #     test_output = emb\n",
    "\n",
    "            #z = test_output1 + test_output2\n",
    "\n",
    "            #num_clusters = 3\n",
    "            #kmeans = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "            #cluster_labels = kmeans.fit_predict(z.cpu().data.numpy())\n",
    "            #cluster_labels = torch.tensor(cluster_labels,dtype=torch.int64).to(device)\n",
    "\n",
    "\n",
    "\n",
    "            pred =  m(test_output).argmax(dim=1)\n",
    "            pred_prob = m(test_output)[:,1]\n",
    "            #pred = cluster_labels\n",
    "            # test_output = test_output.argmax(dim=1)\n",
    "\n",
    "\n",
    "            # y_test = torch.empty(100).random_(2)\n",
    "        #     y_test = torch.tensor(label_3_test).to(device)\n",
    "#             y_test = torch.from_numpy(label_return(dataset_choice ,class_name, \"test\")).to(device)\n",
    "\n",
    "            # import pdb;pdb.set_trace()\n",
    "            y_test = torch.from_numpy(y_test).to(torch.int64).to(device)\n",
    "            correct = (pred  == y_test).sum().item()\n",
    "            accuracy = correct / len(y_test)\n",
    "#             import pdb;pdb.set_trace()\n",
    "            fpr, tpr, thresholds = roc_curve(y_test.cpu().detach().numpy(), pred_prob.cpu().detach().numpy())\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            all_fpr.append(fpr)\n",
    "            all_tpr.append(tpr)\n",
    "            all_roc_auc.append(roc_auc)\n",
    "            all_aucs.append(roc_auc)\n",
    "            \n",
    "            false_positive_indices = np.where((y_test == 0) & (pred.cpu().detach().numpy() == 1))[0]\n",
    "            false_negative_indices = np.where((y_test == 1) & (pred.cpu().detach().numpy() == 0))[0]\n",
    "\n",
    "            false_positives.append(false_positive_indices.tolist())\n",
    "            false_negatives.append(false_negative_indices.tolist())\n",
    "            \n",
    "            cm = confusion_matrix(y_test.cpu().detach().numpy(), pred.cpu().detach().numpy())\n",
    "            plt.figure()\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title(f'Confusion Matrix - Fold {fold + 1}')\n",
    "            plt.xlabel('Predicted Labels')\n",
    "            plt.ylabel('True Labels')\n",
    "\n",
    "\n",
    "\n",
    "#             import pdb;pdb.set_trace()\n",
    "            print(f\"++++Use {model_select} model+++\")\n",
    "            print(calculate_metrics_new(y_test.cpu().detach().numpy(), pred.cpu().detach().numpy() ))\n",
    "            print(\"Loss:\", loss_select, \"class_name\",class_name,\"Accuracy:\", accuracy)\n",
    "            print(classification_report(y_test.cpu().detach().numpy(), pred.cpu().detach().numpy() ))\n",
    "            if datadir == 'pd':\n",
    "                accuracy, precision, recall, fscore, sensivity, specificity, nmi, ari = run_eval(y_test.cpu().detach().numpy(), pred.cpu().detach().numpy())\n",
    "                print(\"acc:\",accuracy, \"precision:\", precision,\"recall:\", recall,\"fscore:\", fscore,\"sensitivity:\", sensivity,\"specificity:\", specificity, \"nmi\", nmi, \"ari\", ari)\n",
    "                # plot_ROC(pred.cpu().detach().numpy() , y_test.cpu().detach().numpy(), 3, classes, skin_type, loss_select)\n",
    "                # print_auc(pred.cpu().detach().numpy() , y_test.cpu().detach().numpy(), 3, category, skin_type, loss_select)\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    for i in range(5):\n",
    "        plt.plot(all_fpr[i], all_tpr[i], lw=2, label=f'ROC curve (area = {all_roc_auc[i]:.2f}) - Fold {i + 1}')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC - All Folds')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()   \n",
    "    \n",
    "    # 计算 AUC 的平均值和标准差\n",
    "    avg_auc = np.mean(all_aucs)\n",
    "    std_auc = np.std(all_aucs)\n",
    "\n",
    "    print(f'Average AUC: {avg_auc:.2f}')\n",
    "    print(f'Standard Deviation of AUC: {std_auc:.2f}')\n",
    "\n",
    "    # 存储 False Positives 和 False Negatives 到 JSON 文件\n",
    "#     result_data = {\n",
    "#         'FalsePositives': false_positives,\n",
    "#         'FalseNegatives': false_negatives\n",
    "#     }\n",
    "\n",
    "#     with open('false_samples.json', 'w') as json_file:\n",
    "#         json.dump(result_data, json_file, indent=4)\n",
    "\n",
    "            \n",
    "def main():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--img_data_dir', type=str, default='pd')\n",
    "#     parser.add_argument('--skin_type', type=str, default='dermatology_images')\n",
    "#     #parser.add_argument('--meta_data_dir', type=str, default='/home/feng/jeding/PD_contrastive_research_0817/meta_ok/')\n",
    "#     parser.add_argument('--model_select', type=str, default='densenet')\n",
    "#     parser.add_argument('--losses_choice', type=str, default='Contrastive_loss')\n",
    "#     parser.add_argument('--dataset_choice', type=str, default='pd')\n",
    "#     parser.add_argument('--category', type=str)\n",
    "#     parser.add_argument('--n_epoch', type=int, default=300)\n",
    "#     parser.add_argument('--n_classes', type=int, default=2)\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "\n",
    "    img_data_dir = 'pd'\n",
    "    skin_type = 'dermatology_images'\n",
    "    losses_choice = 'Contrastive_loss'\n",
    "    model_select = 'densenet'\n",
    "    dataset_choice = 'pd'\n",
    "    category = 'your_category'  # 设置正确的类别值\n",
    "    n_epoch = 300\n",
    "    n_classes = 2\n",
    "\n",
    "    train_eval(img_data_dir, skin_type, losses_choice, model_select, dataset_choice, category, n_epoch, n_classes)\n",
    "#     train_eval(args.img_data_dir, args.skin_type, args.losses_choice, args.model_select, args.dataset_choice,args.category, args.n_epoch, args.n_classes)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jding/anaconda3/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/home/jding/anaconda3/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-62-ac7c19ee4f6a>(43)train_eval()\n",
      "-> for fold, (train_index, test_index) in enumerate(skf.split(image_data_train, y)):\n",
      "(Pdb) y.dtype\n",
      "torch.int64\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-ac7c19ee4f6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-62-ac7c19ee4f6a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0mtrain_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskin_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_choice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_select\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_choice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;31m#     train_eval(args.img_data_dir, args.skin_type, args.losses_choice, args.model_select, args.dataset_choice,args.category, args.n_epoch, args.n_classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-ac7c19ee4f6a>\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m(datadir, skin_type, loss_select, model_select, dataset_choice, category, epoch, n_classes)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mfalse_negatives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 用于存储 False Negatives 的样本 ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Fold {fold + 1}/{5}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-ac7c19ee4f6a>\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m(datadir, skin_type, loss_select, model_select, dataset_choice, category, epoch, n_classes)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mfalse_negatives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 用于存储 False Negatives 的样本 ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Fold {fold + 1}/{5}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def train_eval(datadir,skin_type, loss_select, model_select , dataset_choice ,category, epoch, n_classes):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   \n",
    "    torch.cuda.is_available()\n",
    "    \n",
    "    class_name = 'Dag'\n",
    "    if model_select == 'resnet_18':\n",
    "        model_net = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        # resnet = models.resnet18(pretrained=True)\n",
    "    elif model_select == 'resnet_34':\n",
    "         model_net = models.resnet34(pretrained=True)\n",
    "    elif model_select == 'resnet_50':\n",
    "        model_net = models.resnet50(pretrained=True)\n",
    "    elif model_select == 'densenet':\n",
    "         model_net = models.densenet121(pretrained=True)\n",
    "        \n",
    "    #resnet = models.alexnet(pretrained=True)\n",
    "    \n",
    "    model_net = model_net.to(device)\n",
    "    # 将最后一层的输出维度修改为类别数目\n",
    "    num_classes = 1024\n",
    "    \n",
    "    # num_features = model_net.fc.in_features #512 # Resnet\n",
    "    num_features = model_net.classifier.in_features # Desnet101\n",
    "    # import pdb;pdb.set_trace()\n",
    "    # model_net.fc = nn.Linear(num_features, num_classes) #512 # Resnet\n",
    "    # model_net.fc = model_net.fc.to(device) #512 # Resnet\n",
    "    model_net.classifier = nn.Linear(num_features, num_classes) #desnet\n",
    "    image_data_train, feature_data_train, adj_train_img, adj_f_knn_train, image_data_test, test_feature_data, adj_test_img, adj_f_knn_test = dataloader(datadir,skin_type)\n",
    "    y = torch.tensor(label_return(dataset_choice, class_name, \"train\")).to(device)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    all_aucs = []\n",
    "    all_fpr = []\n",
    "    all_tpr = []\n",
    "    all_roc_auc = []\n",
    "    false_positives = []  # 用于存储 False Positives 的样本 ID\n",
    "    false_negatives = []  # 用于存储 False Negatives 的样本 ID\n",
    "    import pdb;pdb.set_trace()\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(image_data_train, y)):\n",
    "        print(f\"Fold {fold + 1}/{5}:\")\n",
    "        \n",
    "        train_data, test_data = image_data_train[train_index], image_data_train[test_index]\n",
    "        train_features, test_features = feature_data_train[train_index], feature_data_train[test_index]\n",
    "        train_adj_img, test_adj_img = adj_train_img[train_index], adj_train_img[test_index]\n",
    "        train_adj_f_knn, test_adj_f_knn = adj_f_knn_train[train_index], adj_f_knn_train[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "\n",
    "#     \n",
    "\n",
    "        projection = Projection(262, 3)\n",
    "        if datadir == 'skin':\n",
    "            model = Model_SKIN(projection, model_net, n_classes).to(device)\n",
    "        elif datadir == 'abide':\n",
    "            model = Model_ABIDE(projection, model_net, n_classes).to(device)\n",
    "        elif datadir == 'pd':\n",
    "            model = Model_PD(projection, model_net, n_classes).to(device)\n",
    "\n",
    "        class_weights = torch.full((1,n_classes),0.5).view(-1)\n",
    "        criterion1 = WeightedCrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "        if loss_select == 'Contrastive_loss':\n",
    "             criterion2 = contrastive_loss\n",
    "\n",
    "        elif loss_select == 'MGEC_loss':\n",
    "            criterion2 = MGECLoss()\n",
    "\n",
    "        elif loss_select == 'InfoNCE_loss':\n",
    "            criterion2 = info_loss\n",
    "\n",
    "        elif loss_select == 'SAC_loss':\n",
    "            criterion2 = SACLoss()\n",
    "\n",
    "    # criterion3 = loss_dependence\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        n_epochs = epoch\n",
    "\n",
    "        training_range = tqdm(range(n_epochs))\n",
    "\n",
    "        for epoch in training_range:\n",
    "            optimizer.zero_grad()\n",
    "            # cnn_z  =  cnn_encoder(image_data)\n",
    "            # 前向传播\n",
    "\n",
    "            image_data_train = image_data_train.to(device)\n",
    "            feature_data_train = feature_data_train.to(device)\n",
    "            adj_train_img = adj_train_img.to(device)\n",
    "            adj_f_knn_train = adj_f_knn_train.to(device)\n",
    "\n",
    "            output1, output2, emb = model(image_data_train , feature_data_train,adj_train_img, adj_f_knn_train)\n",
    "\n",
    "            \n",
    "\n",
    "            loss_ce1 = criterion1(output1, y)\n",
    "            loss_ce2 = criterion1(output2, y)\n",
    "            alpha = 0.4\n",
    "\n",
    "            if loss_select == 'Contrastive_loss':\n",
    "                adj = adj_train_img +  adj_f_knn_train\n",
    "                diag = torch.diag(adj.sum(dim=1))\n",
    "                loss_extra = criterion2( emb, adj_train_img, adj_f_knn_train, y, output1, output2, diag).to(device)\n",
    "                loss = (1-alpha)*(loss_ce1 + loss_ce2) + alpha* loss_extra\n",
    "\n",
    "            elif loss_select == 'MGEC_loss':\n",
    "                adj = adj_train_img +  adj_f_knn_train\n",
    "                diag = torch.diag(adj.sum(dim=1))\n",
    "                loss_extra = criterion2(output1, output2, adj, diag )\n",
    "                loss = (1-alpha)*(loss_ce1+loss_ce2) + alpha* loss_extra\n",
    "                #loss = loss_extra\n",
    "\n",
    "            elif loss_select == 'InfoNCE_loss':\n",
    "                loss_extra = criterion2( emb, adj_train_img, adj_f_knn_train, y)\n",
    "                loss = (1-alpha)*(loss_ce1+loss_ce2) + alpha* loss_extra\n",
    "\n",
    "            elif loss_select == 'SAC_loss':    \n",
    "                adj = adj_train_img +  adj_f_knn_train\n",
    "                diag = torch.diag(adj.sum(dim=1))\n",
    "                loss_extra = criterion2(emb, adj)\n",
    "                loss = (1-alpha)*(loss_ce1+loss_ce2) + alpha* loss_extra\n",
    "            elif loss_select == 'only_CE':\n",
    "                loss = loss_ce1 + loss_ce2\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # torch.save(model,f'{skin_type}_{epoch}epoch_save.pt')\n",
    "            # print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, n_epochs, loss.item()))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # import pdb;pdb.set_trace()\n",
    "            image_data_test = image_data_test.to(device)\n",
    "            test_feature_data = test_feature_data.to(device)\n",
    "            adj_test_img = adj_test_img.to(device)\n",
    "            adj_f_knn_test = adj_f_knn_test.to(device)\n",
    "\n",
    "            test_output1, test_output2, emb  = model(image_data_test, test_feature_data , adj_test_img, adj_f_knn_test )\n",
    "\n",
    "            # test_output1  = model(test_image_data, test_adjacency_matrix, adj_test_img )\n",
    "            m = nn.Softmax(dim=1)\n",
    "            # import pdb;pdb.set_trace()\n",
    "            test_output = test_output1 + test_output2\n",
    "        #     test_output = emb\n",
    "\n",
    "            #z = test_output1 + test_output2\n",
    "\n",
    "            #num_clusters = 3\n",
    "            #kmeans = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "            #cluster_labels = kmeans.fit_predict(z.cpu().data.numpy())\n",
    "            #cluster_labels = torch.tensor(cluster_labels,dtype=torch.int64).to(device)\n",
    "\n",
    "\n",
    "\n",
    "            pred =  m(test_output).argmax(dim=1)\n",
    "            pred_prob = m(test_output)[:,1]\n",
    "            #pred = cluster_labels\n",
    "            # test_output = test_output.argmax(dim=1)\n",
    "\n",
    "\n",
    "            # y_test = torch.empty(100).random_(2)\n",
    "        #     y_test = torch.tensor(label_3_test).to(device)\n",
    "            y_test = torch.from_numpy(label_return(dataset_choice ,class_name, \"test\")).to(device)\n",
    "\n",
    "            # import pdb;pdb.set_trace()\n",
    "            correct = (pred  == y_test).sum().item()\n",
    "            accuracy = correct / len(y_test)\n",
    "#             import pdb;pdb.set_trace()\n",
    "            fpr, tpr, thresholds = roc_curve(y_test.cpu().detach().numpy(), pred_prob.cpu().detach().numpy())\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            all_fpr.append(fpr)\n",
    "            all_tpr.append(tpr)\n",
    "            all_roc_auc.append(roc_auc)\n",
    "            all_aucs.append(roc_auc)\n",
    "            \n",
    "            false_positive_indices = np.where((y_test == 0) & (pred.cpu().detach().numpy() == 1))[0]\n",
    "            false_negative_indices = np.where((y_test == 1) & (pred.cpu().detach().numpy() == 0))[0]\n",
    "\n",
    "            false_positives.append(false_positive_indices.tolist())\n",
    "            false_negatives.append(false_negative_indices.tolist())\n",
    "            \n",
    "            cm = confusion_matrix(y_test.cpu().detach().numpy(), pred.cpu().detach().numpy())\n",
    "            plt.figure()\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title(f'Confusion Matrix - Fold {fold + 1}')\n",
    "            plt.xlabel('Predicted Labels')\n",
    "            plt.ylabel('True Labels')\n",
    "\n",
    "\n",
    "\n",
    "#             import pdb;pdb.set_trace()\n",
    "            print(f\"++++Use {model_select} model+++\")\n",
    "            print(calculate_metrics_new(y_test.cpu().detach().numpy(), pred.cpu().detach().numpy() ))\n",
    "            print(\"Loss:\", loss_select, \"class_name\",class_name,\"Accuracy:\", accuracy)\n",
    "            print(classification_report(y_test.cpu().detach().numpy(), pred.cpu().detach().numpy() ))\n",
    "            if datadir == 'pd':\n",
    "                accuracy, precision, recall, fscore, sensivity, specificity, nmi, ari = run_eval(y_test.cpu().detach().numpy(), pred.cpu().detach().numpy())\n",
    "                print(\"acc:\",accuracy, \"precision:\", precision,\"recall:\", recall,\"fscore:\", fscore,\"sensitivity:\", sensivity,\"specificity:\", specificity, \"nmi\", nmi, \"ari\", ari)\n",
    "                # plot_ROC(pred.cpu().detach().numpy() , y_test.cpu().detach().numpy(), 3, classes, skin_type, loss_select)\n",
    "                # print_auc(pred.cpu().detach().numpy() , y_test.cpu().detach().numpy(), 3, category, skin_type, loss_select)\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    for i in range(5):\n",
    "        plt.plot(all_fpr[i], all_tpr[i], lw=2, label=f'ROC curve (area = {all_roc_auc[i]:.2f}) - Fold {i + 1}')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC - All Folds')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()   \n",
    "    \n",
    "    # 计算 AUC 的平均值和标准差\n",
    "    avg_auc = np.mean(all_aucs)\n",
    "    std_auc = np.std(all_aucs)\n",
    "\n",
    "    print(f'Average AUC: {avg_auc:.2f}')\n",
    "    print(f'Standard Deviation of AUC: {std_auc:.2f}')\n",
    "\n",
    "    # 存储 False Positives 和 False Negatives 到 JSON 文件\n",
    "#     result_data = {\n",
    "#         'FalsePositives': false_positives,\n",
    "#         'FalseNegatives': false_negatives\n",
    "#     }\n",
    "\n",
    "#     with open('false_samples.json', 'w') as json_file:\n",
    "#         json.dump(result_data, json_file, indent=4)\n",
    "\n",
    "            \n",
    "def main():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--img_data_dir', type=str, default='pd')\n",
    "#     parser.add_argument('--skin_type', type=str, default='dermatology_images')\n",
    "#     #parser.add_argument('--meta_data_dir', type=str, default='/home/feng/jeding/PD_contrastive_research_0817/meta_ok/')\n",
    "#     parser.add_argument('--model_select', type=str, default='densenet')\n",
    "#     parser.add_argument('--losses_choice', type=str, default='Contrastive_loss')\n",
    "#     parser.add_argument('--dataset_choice', type=str, default='pd')\n",
    "#     parser.add_argument('--category', type=str)\n",
    "#     parser.add_argument('--n_epoch', type=int, default=300)\n",
    "#     parser.add_argument('--n_classes', type=int, default=2)\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "\n",
    "    img_data_dir = 'pd'\n",
    "    skin_type = 'dermatology_images'\n",
    "    losses_choice = 'Contrastive_loss'\n",
    "    model_select = 'densenet'\n",
    "    dataset_choice = 'pd'\n",
    "    category = 'your_category'  # 设置正确的类别值\n",
    "    n_epoch = 300\n",
    "    n_classes = 2\n",
    "\n",
    "    train_eval(img_data_dir, skin_type, losses_choice, model_select, dataset_choice, category, n_epoch, n_classes)\n",
    "#     train_eval(args.img_data_dir, args.skin_type, args.losses_choice, args.model_select, args.dataset_choice,args.category, args.n_epoch, args.n_classes)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'false_positives' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-b5a5df79e75a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfalse_positive_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_negative_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_positives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_negatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_positive_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 从测试数据中获取图像\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#             image.save(f'false_positives_fold{fold + 1}_sample{i + 1}.png')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'false_positives' is not defined"
     ]
    }
   ],
   "source": [
    "for fold, (false_positive_indices, false_negative_indices) in enumerate(zip(false_positives, false_negatives)):\n",
    "        for i, idx in enumerate(false_positive_indices):\n",
    "            image = Image.fromarray(test_data[idx])  # 从测试数据中获取图像\n",
    "#             image.save(f'false_positives_fold{fold + 1}_sample{i + 1}.png')\n",
    "\n",
    "#         for i, idx in enumerate(false_negative_indices):\n",
    "#             image = Image.fromarray(test_data[idx])  # 从测试数据中获取图像\n",
    "#             image.save(f'false_negatives_fold{fold + 1}_sample{i + 1}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define your model training and evaluation code here as 'train_eval' function\n",
    "\n",
    "# def train_eval(datadir, skin_type, loss_select, model_select, dataset_choice, category, epoch, n_classes):\n",
    "    # Your existing training and evaluation code here...\n",
    "\n",
    "# Define a function to perform k-fold cross-validation\n",
    "img_data_dir = 'pd'\n",
    "skin_type = 'dermatology_images'\n",
    "losses_choice = 'Contrastive_loss'\n",
    "model_select = 'densenet'\n",
    "dataset_choice = 'pd'\n",
    "category = 'your_category'  # 设置正确的类别值\n",
    "n_epoch = 3\n",
    "n_classes = 2\n",
    "\n",
    "train_eval(img_data_dir, skin_type, losses_choice, model_select, dataset_choice, category, n_epoch, n_classes)\n",
    "\n",
    "def k_fold_cross_validation(X, y, classifier_name, model, num_folds):\n",
    "    conf_matrix = {}\n",
    "    fig, ax = plt.subplots(figsize=(28, 5), nrows=1)\n",
    "    \n",
    "    print(f'Running {classifier_name} classification')\n",
    "\n",
    "    k_accuracy = np.zeros((num_folds))\n",
    "    conf_mat = np.zeros((2, 2))\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=num_folds)\n",
    "    for k, (train, test) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X[train], X[test]\n",
    "        y_train, y_test = y[train], y[test]\n",
    "\n",
    "        train_eval(datadir, skin_type, loss_select, model_select, dataset_choice, category, epoch, n_classes)\n",
    "\n",
    "        # Perform model training and evaluation for each fold\n",
    "        # You may need to pass the appropriate data to the 'train_eval' function\n",
    "\n",
    "        # Compute metrics and plot ROC curve for this fold\n",
    "\n",
    "    # Calculate mean ROC and plot\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "    ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "            label=f'Mean ROC (AUC={np.round(mean_auc, 2)} +/- {np.round(std_auc, 2)})',\n",
    "            lw=2, alpha=.8)\n",
    "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                    label=f'+/- 1 std. dev.')\n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title=f'{classifier_name} ROC')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    conf_matrix[classifier_name] = conf_mat\n",
    "\n",
    "    # Print cross-validated results\n",
    "    print(f\"{num_folds}-fold cross-validated accuracy: {np.round(np.mean(k_accuracy), 5) * 100}%\")\n",
    "    print(k_accuracy)\n",
    "    print()\n",
    "\n",
    "    # Train the classifier with the full data\n",
    "\n",
    "# Load your data (X and y) here\n",
    "# X: observation x features matrix\n",
    "# y: list of labels\n",
    "# classifier_name: Name of your classifier (e.g., \"ResNet-18\")\n",
    "# model: Your machine learning model\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "k_fold_cross_validation(X, y, model_select, model, num_folds)\n",
    "\n",
    "# Plot and show ROC curve here\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !bash -c \"/home/jding/Documents/PD_contrastive_research_0817/run_exp_pd.sh\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
